}
# Load the libraries
library(httr)
library(jsonlite)
# Specify the URL
url <- "http://snomed.info/sct?fhir_vs=ecl/%3C%20700097003%20"
# Make the HTTP GET request
response <- httr::GET(url)
# Check if the request was successful (status code 200)
if (httr::status_code(response) == 200) {
# Parse the JSON content
valueset <- jsonlite::fromJSON(httr::content(response, "text"))
# Save the valueset to a JSON file
jsonlite::write_json(valueset, "valueset.json", pretty = TRUE)
} else {
cat("Error:", httr::status_code(response), httr::content(response, "text"), "\n")
}
if (httr::status_code(response) == 200) {
# Parse the JSON content
valueset <- jsonlite::fromJSON(httr::content(response, "text"))
# Save the valueset to a JSON file
jsonlite::write_json(valueset, "valueset.json", pretty = TRUE)
} else {
cat("Error:", httr::status_code(response), httr::content(response, "text"), "\n")
}
library(xml2)
library(httr)
# Specify the URL
url <- "http://decor.nictiz.nl/fhir/4.0/zib2015bbr-/ValueSet/2.16.840.1.113883.2.4.3.11.60.40.2.7.3.2--20150401000000"
# Download the content from the URL
response <- GET(url)
content <- content(response, "text")
# Parse the XML content
xml_content <- read_xml(content)
# Define the namespaces
ns <- c(
fhir = "http://hl7.org/fhir",
snomed = "http://snomed.info/sct"
)
# Extract system and code pairs
system_code_pairs <- xml_content %>%
xml_find_all(".//snomed:concept", ns) %>%
xml_attr("system") %>%
paste(xml_find_all(".//snomed:code", ns) %>% xml_text(), sep = ":")
library(tidyverse)
# Extract system and code pairs
system_code_pairs <- xml_content %>%
xml_find_all(".//snomed:concept", ns) %>%
xml_attr("system") %>%
paste(xml_find_all(".//snomed:code", ns) %>% xml_text(), sep = ":")
# Install and load required packages
install.packages(c("jsonlite", "tidyjson", "dplyr"))
library(jsonlite)
library(tidyjson)
library(dplyr)
# Define the FHIR API link
R4link <- "http://decor.nictiz.nl/fhir/4.0/san-gen-/ValueSet/2.16.840.1.113883.2.4.3.11.60.124.11.2--20240102090048"
R4jsonlink <- paste0(R4link, "?_format=json")
# Read JSON data
R4AL <- read_json(R4jsonlink)
install.packages(c("jsonlite", "tidyjson", "dplyr"))
library(jsonlite)
library(tidyjson)
library(dplyr)
# Define the FHIR API link
R4link <- "http://decor.nictiz.nl/fhir/4.0/san-gen-/ValueSet/2.16.840.1.113883.2.4.3.11.60.124.11.2--20240102090048"
R4jsonlink <- paste0(R4link, "?_format=json")
# Read JSON data
R4AL <- read_json(R4jsonlink)
names(R4AL)
# Read JSON data
R4AL <- read_json(R4jsonlink)
# Install and load required packages
install.packages(c("jsonlite", "tidyjson", "dplyr"))
library(jsonlite)
library(dplyr)
# Define the FHIR API link
R4link <- "http://decor.nictiz.nl/fhir/4.0/san-gen-/ValueSet/2.16.840.1.113883.2.4.3.11.60.124.11.2--20240102090048"
R4jsonlink <- paste0(R4link, "?_format=json")
# Read JSON data
R4AL <- read_json(R4jsonlink)
library(jsonlite)
library(dplyr)
# Define the FHIR API link
R4link <- "http://decor.nictiz.nl/fhir/4.0/san-gen-/ValueSet/2.16.840.1.113883.2.4.3.11.60.124.11.2--20240102090048"
R4jsonlink <- paste0(R4link, "?_format=json")
# Read JSON data
R4AL <- read_json(R4jsonlink)
library(jsonlite)
library(dplyr)
# Define the FHIR API link
R4link <- "http://decor.nictiz.nl/fhir/4.0/san-gen-/ValueSet/2.16.840.1.113883.2.4.3.11.60.124.11.2--20240102090048"
R4jsonlink <- paste0(R4link, "?_format=json")
# Read JSON data
R4AL <- read_json(R4jsonlink)
library(jsonlite)
library(dplyr)
# Define the FHIR API link
R4link <- "http://decor.nictiz.nl/fhir/4.0/san-gen-/ValueSet/2.16.840.1.113883.2.4.3.11.60.124.11.2--20240102090048"
R4jsonlink <- paste0(R4link, "?_format=json")
# Read JSON data
R4AL <- read_json(R4jsonlink)
names(R4AL)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
enter_object("compose") %>%
spread_all()
View(flattened_data)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json()
names(flattened_data)
View(flattened_data)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
enter_object("..JSON")
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
enter_object("..JSON") %>%
spread_all()
View(flattened_data)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json()
View(flattened_data)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
filter(nrow()==16)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
filter(row_number()==16)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
filter(row_number()==16)%>%
spread_all()
View(flattened_data)
library(tidyjson)
# Flatten the JSON data
flattened_data <- R4AL %>%
as.tbl_json() %>%
filter(row_number()==16)%>%
spread_all() %>%
as.data.frame()
View(flattened_data)
R4AL<-R4AL|>
tibble()
R4jsonlink<- paste0(R4link, "?_format=json")
R4AL<-read_json(R4jsonlink)
#Parse Questionnaire_New
#~Saves Questionnaire+ValueSet resources as json in R4json subfolder
#~Parses Questionnaire Json to flat csv + saves in R4csv subfolder
#~Updates Repo files
#~Logs and saves script instance under Questionnaire name
#Author: j.hendrikx@santeon.nl
#~remove all objects from the current workspace to start with a clean slate
rm(list = ls())
#Log start run####
rundate<-(paste("#Start of Analysis - System time ", Sys.time()))
#System config####
#install.packages("tidyverse")
#installed.packages("jsonlite")
#Load packages
library(tidyverse)
library(jsonlite)
library(stringr)
#Create generic functions
# Function to remove leading and trailing whitespace from all strings in a dataframe
trim_df <- function(df) {
# Apply trimws to all columns of the dataframe
df[] <- lapply(df, function(x) if(is.character(x)) trimws(x) else x)
return(df)
}
#set paths for different working stations
#Home
wdHomeTeams ="C:\\Users\\joshe\\Santeon\\PB IenI - General\\Development\\SIM\\SIM-on-FHIR\\"
wdHomeRepo ="C:\\Users\\joshe\\Repos\\HipsETL\\"
#Santeon laptop
wdLaptopTeams ="C:\\Users\\j.hendrikx\\Santeon\\PB IenI - General\\Development\\SIM\\"
wdLaptopRepo ="C:\\Users\\j.hendrikx\\Repos\\HipsETL\\"
#Santeon remote desktop
wdSRD ="S:\\VBHC\\VBHC-Centraal\\SIM\\"
wdSRDRepo="C:\\Users\\j.vanderlinden\\Documents\\HipsETL\\"
# Input Parameters####
#~Set working directory paths#####
wd<-wdHomeTeams
setwd(wd)
#Load ConceptMaps
library(readr)
ZibToFHIRtypeMap <- read_delim("C:/Users/joshe/Santeon/PB IenI - General/Development/SIM/SIM-on-FHIR/ZibToFHIRtypeMap.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#~Set transaction url####
# FHIR transaction URL
#copy link from https://decor.nictiz.nl/ad/#/san-gen-/project/project-index/transactions ' Column FHIR >R4'
#urltrans<-"http://decor.nictiz.nl/fhir/4.0/sansa-/StructureDefinition/2.16.840.1.113883.2.4.3.11.60.909.4.41--20240320000000?_format=json"
#DECOR transaction url (non-FHIR) as backup if FHIR export is down
#copy link from https://decor.nictiz.nl/ad/#/san-gen-/project/project-index/transactions ' Column Decor JSON'
urltrans2<-"http://decor.nictiz.nl/decor/services/RetrieveTransaction?id=2.16.840.1.113883.2.4.3.11.60.909.4.41&effectiveDate=2024-03-20T00%3A00%3A00&language=nl-NL&ui=nl-NL&format=json"
#DECOR transaction AD-API call####
trans<-read_json(paste0(urltrans2))
#~DECOR parse transaction for generating FHIR Bulk API Query####
#Get types###
types<- tryCatch({
trans|>
tibble()%>%
unnest_longer(trans)%>%
unnest_longer(trans)%>%
select(trans)%>%
filter(row_number()==length(trans))%>%
unnest_longer(trans)%>%
unnest_wider(trans, names_sep = ".")%>% #model/type level
select(trans.shortName)
}, error = function(e) {
message("Top level nested valuesets not present", e$message)
return(NULL)
})
#join available types with conceptmap if present
if (!is.null(types) ) { #check if null or empty df due to filtering displays/groups
types <- types %>%
left_join(ZibToFHIRtypeMap, by = 'trans.shortName',suffix=c("",".drop"),copy=TRUE,relationship = 'one-to-one')%>%
select(-contains(".drop"))
} else {
message("Skipping Qtrans join: AnswerLists not present.")
}
querytype<-paste0(types[["trans.type"]], collapse = ",")
query<-paste0("/Patient/$export?_type=",querytype,"&")
print(query)
#Save updated local files & remove object in R
writeLines(query,"exportquery.txt")
#Parse Questionnaire_New
#~Saves Questionnaire+ValueSet resources as json in R4json subfolder
#~Parses Questionnaire Json to flat csv + saves in R4csv subfolder
#~Updates Repo files
#~Logs and saves script instance under Questionnaire name
#Author: j.hendrikx@santeon.nl
#~remove all objects from the current workspace to start with a clean slate
rm(list = ls())
#Log start run####
rundate<-(paste("#Start of Analysis - System time ", Sys.time()))
#System config####
#install.packages("tidyverse")
#installed.packages("jsonlite")
#Load packages
library(tidyverse)
library(jsonlite)
library(stringr)
#Create generic functions
# Function to remove leading and trailing whitespace from all strings in a dataframe
trim_df <- function(df) {
# Apply trimws to all columns of the dataframe
df[] <- lapply(df, function(x) if(is.character(x)) trimws(x) else x)
return(df)
}
#set paths for different working stations
#Home
wdHomeTeams ="C:\\Users\\joshe\\Santeon\\PB IenI - General\\Development\\SIM\\SIM-on-FHIR\\"
wdHomeRepo ="C:\\Users\\joshe\\Repos\\HipsETL\\"
#Santeon laptop
wdLaptopTeams ="C:\\Users\\j.hendrikx\\Santeon\\PB IenI - General\\Development\\SIM\\"
wdLaptopRepo ="C:\\Users\\j.hendrikx\\Repos\\HipsETL\\"
#Santeon remote desktop
wdSRD ="S:\\VBHC\\VBHC-Centraal\\SIM\\"
wdSRDRepo="C:\\Users\\j.vanderlinden\\Documents\\HipsETL\\"
# Input Parameters####
#~Set working directory paths#####
wd<-wdHomeTeams
setwd(wd)
#Load ConceptMaps
library(readr)
ZibToFHIRtypeMap <- read_delim("C:/Users/joshe/Santeon/PB IenI - General/Development/SIM/SIM-on-FHIR/ZibToFHIRtypeMap.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#Parse Questionnaire_New
#~Saves Questionnaire+ValueSet resources as json in R4json subfolder
#~Parses Questionnaire Json to flat csv + saves in R4csv subfolder
#~Updates Repo files
#~Logs and saves script instance under Questionnaire name
#Author: j.hendrikx@santeon.nl
#~remove all objects from the current workspace to start with a clean slate
rm(list = ls())
#Log start run####
rundate<-(paste("#Start of Analysis - System time ", Sys.time()))
#System config####
#install.packages("tidyverse")
#installed.packages("jsonlite")
#Load packages
library(tidyverse)
library(jsonlite)
library(stringr)
#Create generic functions
# Function to remove leading and trailing whitespace from all strings in a dataframe
trim_df <- function(df) {
# Apply trimws to all columns of the dataframe
df[] <- lapply(df, function(x) if(is.character(x)) trimws(x) else x)
return(df)
}
#set paths for different working stations
#Home
wdHomeTeams ="C:\\Users\\joshe\\Santeon\\PB IenI - General\\Development\\SIM\\SIM-on-FHIR\\"
wdHomeRepo ="C:\\Users\\joshe\\Repos\\sim-on-fhir\\BulkEport\\"
#Santeon laptop
wdLaptopTeams ="C:\\Users\\j.hendrikx\\Santeon\\PB IenI - General\\Development\\SIM\\"
wdLaptopRepo ="C:\\Users\\j.hendrikx\\Repos\\HipsETL\\"
#Santeon remote desktop
wdSRD ="S:\\VBHC\\VBHC-Centraal\\SIM\\"
wdSRDRepo="C:\\Users\\j.vanderlinden\\Documents\\HipsETL\\"
# Input Parameters####
#~Set working directory paths#####
wd<-wdHomeTeams
setwd(wd)
#Load ConceptMaps
library(readr)
ZibToFHIRtypeMap <- read_delim("C:/Users/joshe/Santeon/PB IenI - General/Development/SIM/SIM-on-FHIR/ZibToFHIRtypeMap.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#Parse Questionnaire_New
#~Saves Questionnaire+ValueSet resources as json in R4json subfolder
#~Parses Questionnaire Json to flat csv + saves in R4csv subfolder
#~Updates Repo files
#~Logs and saves script instance under Questionnaire name
#Author: j.hendrikx@santeon.nl
#~remove all objects from the current workspace to start with a clean slate
rm(list = ls())
#Log start run####
rundate<-(paste("#Start of Analysis - System time ", Sys.time()))
#System config####
#install.packages("tidyverse")
#installed.packages("jsonlite")
#Load packages
library(tidyverse)
library(jsonlite)
library(stringr)
#Create generic functions
# Function to remove leading and trailing whitespace from all strings in a dataframe
trim_df <- function(df) {
# Apply trimws to all columns of the dataframe
df[] <- lapply(df, function(x) if(is.character(x)) trimws(x) else x)
return(df)
}
#set paths for different working stations
#Home
wdHomeTeams ="C:\\Users\\joshe\\Santeon\\PB IenI - General\\Development\\SIM\\SIM-on-FHIR\\"
wdHomeRepo ="C:\\Users\\joshe\\Repos\\sim-on-fhir\\BulkEport\\"
#Santeon laptop
wdLaptopTeams ="C:\\Users\\j.hendrikx\\Santeon\\PB IenI - General\\Development\\SIM\\"
wdLaptopRepo ="C:\\Users\\j.hendrikx\\Repos\\HipsETL\\"
#Santeon remote desktop
wdSRD ="S:\\VBHC\\VBHC-Centraal\\SIM\\"
wdSRDRepo="C:\\Users\\j.vanderlinden\\Documents\\HipsETL\\"
# Input Parameters####
#~Set working directory paths#####
wd<-wdHomeRepo
setwd(wd)
#Load ConceptMaps
library(readr)
ZibToFHIRtypeMap <- read_delim("C:/Users/joshe/Santeon/PB IenI - General/Development/SIM/SIM-on-FHIR/ZibToFHIRtypeMap.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#Parse Questionnaire_New
#~Saves Questionnaire+ValueSet resources as json in R4json subfolder
#~Parses Questionnaire Json to flat csv + saves in R4csv subfolder
#~Updates Repo files
#~Logs and saves script instance under Questionnaire name
#Author: j.hendrikx@santeon.nl
#~remove all objects from the current workspace to start with a clean slate
rm(list = ls())
#Log start run####
rundate<-(paste("#Start of Analysis - System time ", Sys.time()))
#System config####
#install.packages("tidyverse")
#installed.packages("jsonlite")
#Load packages
library(tidyverse)
library(jsonlite)
library(stringr)
#Create generic functions
# Function to remove leading and trailing whitespace from all strings in a dataframe
trim_df <- function(df) {
# Apply trimws to all columns of the dataframe
df[] <- lapply(df, function(x) if(is.character(x)) trimws(x) else x)
return(df)
}
#set paths for different working stations
#Home
wdHomeTeams ="C:\\Users\\joshe\\Santeon\\PB IenI - General\\Development\\SIM\\SIM-on-FHIR\\"
wdHomeRepo ="C:\\Users\\joshe\\Repos\\sim-on-fhir\\BulkEport\\"
#Santeon laptop
wdLaptopTeams ="C:\\Users\\j.hendrikx\\Santeon\\PB IenI - General\\Development\\SIM\\"
wdLaptopRepo ="C:\\Users\\j.hendrikx\\Repos\\HipsETL\\"
#Santeon remote desktop
wdSRD ="S:\\VBHC\\VBHC-Centraal\\SIM\\"
wdSRDRepo="C:\\Users\\j.hendrikx\\Documents\\HipsETL\\"
# Input Parameters####
#~Set working directory paths#####
wd<-wdHomeRepo
setwd(wd)
#Load ConceptMaps
library(readr)
ZibToFHIRtypeMap <- read_delim("~/ZibToFHIRtypeMap.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#Parse Questionnaire_New
#~Saves Questionnaire+ValueSet resources as json in R4json subfolder
#~Parses Questionnaire Json to flat csv + saves in R4csv subfolder
#~Updates Repo files
#~Logs and saves script instance under Questionnaire name
#Author: j.hendrikx@santeon.nl
#~remove all objects from the current workspace to start with a clean slate
rm(list = ls())
#Log start run####
rundate<-(paste("#Start of Analysis - System time ", Sys.time()))
#System config####
#install.packages("tidyverse")
#installed.packages("jsonlite")
#Load packages
library(tidyverse)
library(jsonlite)
library(stringr)
#Create generic functions
# Function to remove leading and trailing whitespace from all strings in a dataframe
trim_df <- function(df) {
# Apply trimws to all columns of the dataframe
df[] <- lapply(df, function(x) if(is.character(x)) trimws(x) else x)
return(df)
}
#set paths for different working stations
#Home
wdHomeTeams ="C:\\Users\\joshe\\Santeon\\PB IenI - General\\Development\\SIM\\SIM-on-FHIR\\"
wdHomeRepo ="C:\\Users\\joshe\\Repos\\sim-on-fhir\\BulkEport\\"
#Santeon laptop
wdLaptopTeams ="C:\\Users\\j.hendrikx\\Santeon\\PB IenI - General\\Development\\SIM\\"
wdLaptopRepo ="C:\\Users\\j.hendrikx\\Repos\\HipsETL\\"
#Santeon remote desktop
wdSRD ="S:\\VBHC\\VBHC-Centraal\\SIM\\"
wdSRDRepo="C:\\Users\\j.hendrikx\\Documents\\HipsETL\\"
# Input Parameters####
#~Set working directory paths#####
wd<-wdHomeRepo
setwd(wd)
#Load ConceptMaps
library(readr)
ZibToFHIRtypeMap <- read_delim("ZibToFHIRtypeMap.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#~Set transaction url####
# FHIR transaction URL
#copy link from https://decor.nictiz.nl/ad/#/san-gen-/project/project-index/transactions ' Column FHIR >R4'
#urltrans<-"http://decor.nictiz.nl/fhir/4.0/sansa-/StructureDefinition/2.16.840.1.113883.2.4.3.11.60.909.4.41--20240320000000?_format=json"
#DECOR transaction url (non-FHIR) as backup if FHIR export is down
#copy link from https://decor.nictiz.nl/ad/#/san-gen-/project/project-index/transactions ' Column Decor JSON'
urltrans2<-"http://decor.nictiz.nl/decor/services/RetrieveTransaction?id=2.16.840.1.113883.2.4.3.11.60.909.4.41&effectiveDate=2024-03-20T00%3A00%3A00&language=nl-NL&ui=nl-NL&format=json"
#DECOR transaction AD-API call####
trans<-read_json(paste0(urltrans2))
#~DECOR parse transaction for generating FHIR Bulk API Query####
#Get types###
types<- tryCatch({
trans|>
tibble()%>%
unnest_longer(trans)%>%
unnest_longer(trans)%>%
select(trans)%>%
filter(row_number()==length(trans))%>%
unnest_longer(trans)%>%
unnest_wider(trans, names_sep = ".")%>% #model/type level
select(trans.shortName)
}, error = function(e) {
message("Top level nested valuesets not present", e$message)
return(NULL)
})
#join available types with conceptmap if present
if (!is.null(types) ) { #check if null or empty df due to filtering displays/groups
types <- types %>%
left_join(ZibToFHIRtypeMap, by = 'trans.shortName',suffix=c("",".drop"),copy=TRUE,relationship = 'one-to-one')%>%
select(-contains(".drop"))
} else {
message("Skipping Qtrans join: AnswerLists not present.")
}
querytype<-paste0(types[["trans.type"]], collapse = ",")
query<-paste0("/Patient/$export?_type=",querytype,"&")
print(query)
#Save updated local files & remove object in R
writeLines(query,"exportquery.txt")
typeFilter<-
trans|>
tibble()%>%
unnest_longer(trans)%>%
unnest_longer(trans)%>%
select(trans)%>%
filter(row_number()==length(trans))%>%
unnest_longer(trans)%>%
unnest_wider(trans, names_sep = ".")%>% #model/type level
select(-trans.id:-trans.iddisplay,-trans.implementation:-trans.terminologyAssociation)%>%
unnest_longer(trans.concept)%>% #element level
unnest_wider(trans.concept)%>%
select(-iddisplay,-implementation,-name,-desc,-valueDomain,-relationship,-operationalization,-terminologyAssociation,-identifierAssociation)%>%
unnest_wider(context,names_sep = ".")%>% #wider to extract context and keep records without context
unnest_wider(context.1)%>% #wider to extract context and keep records without context
select(-language)%>%
rename(filterValueset='#text')%>%
unnest_wider(inherit,names_sep = ".")%>% #add ZIB reference
unnest_wider(inherit.1,names_sep = ".")%>%
select(-inherit.1.ref:-inherit.1.iEffectiveDate)%>% #remove additional reference metadata
rename(zibElement=inherit.1.refdisplay)%>%
select(-valueSet,-concept)
View(typeFilter)
